{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-class case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T03:02:13.642797Z",
     "start_time": "2017-07-19T03:02:13.372379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** binary case balanced ********************\n",
      "cfm: \n",
      " [[1 1]\n",
      " [0 2]]\n",
      "auc:  0.75\n",
      "f1:  0.666666666667\n",
      "accuracy:  0.75\n",
      "******************** binary case unbalanced ********************\n",
      "cfm: \n",
      " [[ 1  1]\n",
      " [ 0 10]]\n",
      "auc:  0.75\n",
      "f1:  0.666666666667\n",
      "accuracy:  0.916666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# binary case, balanced\n",
    "\n",
    "# prepare data\n",
    "y_true = np.array([0,0, 1, 1])\n",
    "y_score = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "y_pred = np.zeros(y_score.shape)\n",
    "y_pred[y_score>.5] = 1\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score, pos_label=1)\n",
    "print('*'*20 + ' binary case balanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[1,0]))\n",
    "print('auc: ', metrics.auc(fpr, tpr))\n",
    "print('f1: ', metrics.f1_score(y_true,y_pred))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))\n",
    "\n",
    "# binary case, in balanced\n",
    "\n",
    "# prepare data\n",
    "y_true = np.hstack([np.hstack([y_true[:2]]*5),y_true[2:]])\n",
    "y_score =  np.hstack([np.hstack([y_score[:2]]*5),y_score[2:]])\n",
    "y_pred = np.zeros(y_score.shape)\n",
    "y_pred[y_score>.5] = 1\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score, pos_label=1)\n",
    "print('*'*20 + ' binary case unbalanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[1,0]))\n",
    "print('auc: ', metrics.auc(fpr, tpr))\n",
    "print('f1: ', metrics.f1_score(y_true,y_pred))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T03:02:13.674765Z",
     "start_time": "2017-07-19T03:02:13.643907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** binary case balanced ********************\n",
      "cfm: \n",
      " [[1 1]\n",
      " [1 1]]\n",
      "auc:  0.75\n",
      "f1:  0.5\n",
      "accuracy:  0.5\n",
      "******************** binary case unbalanced ********************\n",
      "cfm: \n",
      " [[1 1]\n",
      " [5 5]]\n",
      "auc:  0.75\n",
      "f1:  0.25\n",
      "accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "# binary case, balanced\n",
    "\n",
    "# prepare data\n",
    "y_true = np.array([0,0, 1, 1])\n",
    "y_score = np.array([0.1, 0.6, 0.35, 0.8])\n",
    "y_pred = np.zeros(y_score.shape)\n",
    "y_pred[y_score>.5] = 1\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score, pos_label=1)\n",
    "print('*'*20 + ' binary case balanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[1,0]))\n",
    "print('auc: ', metrics.auc(fpr, tpr))\n",
    "print('f1: ', metrics.f1_score(y_true,y_pred))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))\n",
    "\n",
    "# binary case, in balanced\n",
    "\n",
    "# prepare data\n",
    "y_true = np.hstack([np.hstack([y_true[:2]]*5),y_true[2:]])\n",
    "y_score =  np.hstack([np.hstack([y_score[:2]]*5),y_score[2:]])\n",
    "y_pred = np.zeros(y_score.shape)\n",
    "y_pred[y_score>.5] = 1\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score, pos_label=1)\n",
    "print('*'*20 + ' binary case unbalanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[1,0]))\n",
    "print('auc: ', metrics.auc(fpr, tpr))\n",
    "print('f1: ', metrics.f1_score(y_true,y_pred))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T03:02:13.808879Z",
     "start_time": "2017-07-19T03:02:13.675815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** binary case balanced ********************\n",
      "cfm: \n",
      " [[1 1]\n",
      " [1 1]]\n",
      "auc:  0.25\n",
      "f1:  0.5\n",
      "accuracy:  0.5\n",
      "******************** binary case unbalanced ********************\n",
      "cfm: \n",
      " [[5 5]\n",
      " [1 1]]\n",
      "auc:  0.25\n",
      "f1:  0.25\n",
      "accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "# we flip the definition of postive/negative\n",
    "# binary case, balanced\n",
    "\n",
    "# prepare data\n",
    "y_true = np.array([0,0, 1, 1])\n",
    "y_score = np.array([0.1, 0.6, 0.35, 0.8])\n",
    "y_pred = np.zeros(y_score.shape)\n",
    "y_pred[y_score>.5] = 1\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score, pos_label=0)\n",
    "print('*'*20 + ' binary case balanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[0,1]))\n",
    "print('auc: ', metrics.auc(fpr, tpr))\n",
    "print('f1: ', metrics.f1_score(y_true,y_pred))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))\n",
    "\n",
    "# binary case, in balanced\n",
    "\n",
    "# prepare data\n",
    "y_true = np.hstack([np.hstack([y_true[:2]]*5),y_true[2:]])\n",
    "y_score =  np.hstack([np.hstack([y_score[:2]]*5),y_score[2:]])\n",
    "y_pred = np.zeros(y_score.shape)\n",
    "y_pred[y_score>.5] = 1\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score, pos_label=0)\n",
    "print('*'*20 + ' binary case unbalanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[0,1]))\n",
    "print('auc: ', metrics.auc(fpr, tpr))\n",
    "print('f1: ', metrics.f1_score(y_true,y_pred))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three-class case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class ratio: 5:1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T03:02:13.948356Z",
     "start_time": "2017-07-19T03:02:13.809995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** three-class case balanced ********************\n",
      "cfm: \n",
      " [[2 0 0]\n",
      " [0 2 0]\n",
      " [0 1 1]]\n",
      "auc:  [1.0, 1.0, 1.0]\n",
      "micro auc:  0.944444444444\n",
      "macro auc:  1.0\n",
      "f1 :  [ 1.          0.8         0.66666667]\n",
      "micro f1:  0.833333333333\n",
      "macro f1:  0.822222222222\n",
      "weighted f1:  0.822222222222\n",
      "accuracy:  0.833333333333\n",
      "******************** three-class case unbalanced ********************\n",
      "cfm: \n",
      " [[10  0  0]\n",
      " [ 0  2  0]\n",
      " [ 0  1  1]]\n",
      "auc:  [1.0, 1.0, 1.0]\n",
      "micro auc:  0.979591836735\n",
      "macro auc:  1.0\n",
      "f1 :  [ 1.          0.8         0.66666667]\n",
      "micro f1:  0.928571428571\n",
      "macro f1:  0.822222222222\n",
      "weighted f1:  0.92380952381\n",
      "accuracy:  0.928571428571\n"
     ]
    }
   ],
   "source": [
    "# three-class case, balanced\n",
    "\n",
    "# prepare data\n",
    "y_true = np.array([0,0, 1, 1,2, 2])\n",
    "y_score = np.array([[0.5, 0.4, 0.1],\n",
    "                    [0.8,0.1,0.1],\n",
    "                    [0.3,0.6,0.1],\n",
    "                    [0.4,0.5,0.1],\n",
    "                    [0,0.1,0.9],\n",
    "                    [0.3,0.4,0.3]])\n",
    "y_pred = np.argmax(y_score,1)\n",
    "\n",
    "y_true_roc = label_binarize(y_true, classes=[0,1,2])\n",
    "\n",
    "\n",
    "print('*'*20 + ' three-class case balanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[0,1,2]))\n",
    "aucs = []\n",
    "for i in range(3):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score[:,i], pos_label=i)\n",
    "    aucs.append(metrics.auc(fpr, tpr))\n",
    "print('auc: ', aucs)\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_micro, tpr_micro, _ = metrics.roc_curve(y_true_roc.ravel(), y_score.ravel())\n",
    "print('micro auc: ', metrics.auc(fpr_micro, tpr_micro))\n",
    "print('macro auc: ', np.mean(aucs))\n",
    "print('f1 : ', metrics.f1_score(y_true,y_pred,average=None))\n",
    "print('micro f1: ', metrics.f1_score(y_true,y_pred,average='micro'))\n",
    "print('macro f1: ', metrics.f1_score(y_true,y_pred,average='macro'))\n",
    "print('weighted f1: ', metrics.f1_score(y_true,y_pred,average='weighted'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))\n",
    "# three-class case, in balanced\n",
    "\n",
    "# prepare data\n",
    "# duplicate class 0 five times\n",
    "y_true = np.hstack([np.hstack([y_true[:2]]*5),y_true[2:]])\n",
    "y_score =  np.vstack([np.vstack([y_score[:2,:]]*5),y_score[2:,:]])\n",
    "y_pred = np.argmax(y_score,1)\n",
    "\n",
    "y_true_roc = label_binarize(y_true, classes=[0,1,2])\n",
    "\n",
    "    \n",
    "print('*'*20 + ' three-class case unbalanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[0,1,2]))\n",
    "aucs = []\n",
    "for i in range(3):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score[:,i], pos_label=i)\n",
    "    aucs.append(metrics.auc(fpr, tpr))\n",
    "print('auc: ', aucs)\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_micro, tpr_micro, _ = metrics.roc_curve(y_true_roc.ravel(), y_score.ravel())\n",
    "print('micro auc: ', metrics.auc(fpr_micro, tpr_micro))\n",
    "print('macro auc: ', np.mean(aucs))\n",
    "print('f1 : ', metrics.f1_score(y_true,y_pred,average=None))\n",
    "print('micro f1: ', metrics.f1_score(y_true,y_pred,average='micro'))\n",
    "print('macro f1: ', metrics.f1_score(y_true,y_pred,average='macro'))\n",
    "print('weighted f1: ', metrics.f1_score(y_true,y_pred,average='weighted'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T03:02:14.142180Z",
     "start_time": "2017-07-19T03:02:13.949420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** three-class case balanced ********************\n",
      "cfm: \n",
      " [[1 1 0]\n",
      " [0 2 0]\n",
      " [0 1 1]]\n",
      "auc:  [0.75, 1.0, 0.9375]\n",
      "micro auc:  0.875\n",
      "macro auc:  0.895833333333\n",
      "f1 :  [ 0.66666667  0.66666667  0.66666667]\n",
      "micro f1:  0.666666666667\n",
      "macro f1:  0.666666666667\n",
      "weighted f1:  0.666666666667\n",
      "accuracy:  0.666666666667\n",
      "******************** three-class case unbalanced ********************\n",
      "cfm: \n",
      " [[5 5 0]\n",
      " [0 2 0]\n",
      " [0 1 1]]\n",
      "auc:  [0.75, 1.0, 0.89583333333333326]\n",
      "micro auc:  0.839285714286\n",
      "macro auc:  0.881944444444\n",
      "f1 :  [ 0.66666667  0.4         0.66666667]\n",
      "micro f1:  0.571428571429\n",
      "macro f1:  0.577777777778\n",
      "weighted f1:  0.628571428571\n",
      "accuracy:  0.571428571429\n"
     ]
    }
   ],
   "source": [
    "# three-class case, balanced\n",
    "\n",
    "# prepare data\n",
    "y_true = np.array([0,0, 1, 1,2, 2])\n",
    "y_score = np.array([[0.3, 0.4, 0.3],\n",
    "                    [0.8,0.1,0.1],\n",
    "                    [0.3,0.6,0.1],\n",
    "                    [0.4,0.5,0.1],\n",
    "                    [0,0.1,0.9],\n",
    "                    [0.3,0.4,0.3]])\n",
    "y_pred = np.argmax(y_score,1)\n",
    "\n",
    "y_true_roc = label_binarize(y_true, classes=[0,1,2])\n",
    "\n",
    "\n",
    "print('*'*20 + ' three-class case balanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[0,1,2]))\n",
    "aucs = []\n",
    "for i in range(3):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score[:,i], pos_label=i)\n",
    "    aucs.append(metrics.auc(fpr, tpr))\n",
    "print('auc: ', aucs)\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_micro, tpr_micro, _ = metrics.roc_curve(y_true_roc.ravel(), y_score.ravel())\n",
    "print('micro auc: ', metrics.auc(fpr_micro, tpr_micro))\n",
    "print('macro auc: ', np.mean(aucs))\n",
    "print('f1 : ', metrics.f1_score(y_true,y_pred,average=None))\n",
    "print('micro f1: ', metrics.f1_score(y_true,y_pred,average='micro'))\n",
    "print('macro f1: ', metrics.f1_score(y_true,y_pred,average='macro'))\n",
    "print('weighted f1: ', metrics.f1_score(y_true,y_pred,average='weighted'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))\n",
    "# three-class case, in balanced\n",
    "\n",
    "# prepare data\n",
    "# duplicate class 0 five times\n",
    "y_true = np.hstack([np.hstack([y_true[:2]]*5),y_true[2:]])\n",
    "y_score =  np.vstack([np.vstack([y_score[:2,:]]*5),y_score[2:,:]])\n",
    "y_pred = np.argmax(y_score,1)\n",
    "\n",
    "y_true_roc = label_binarize(y_true, classes=[0,1,2])\n",
    "\n",
    "    \n",
    "print('*'*20 + ' three-class case unbalanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[0,1,2]))\n",
    "aucs = []\n",
    "for i in range(3):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score[:,i], pos_label=i)\n",
    "    aucs.append(metrics.auc(fpr, tpr))\n",
    "print('auc: ', aucs)\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_micro, tpr_micro, _ = metrics.roc_curve(y_true_roc.ravel(), y_score.ravel())\n",
    "print('micro auc: ', metrics.auc(fpr_micro, tpr_micro))\n",
    "print('macro auc: ', np.mean(aucs))\n",
    "print('f1 : ', metrics.f1_score(y_true,y_pred,average=None))\n",
    "print('micro f1: ', metrics.f1_score(y_true,y_pred,average='micro'))\n",
    "print('macro f1: ', metrics.f1_score(y_true,y_pred,average='macro'))\n",
    "print('weighted f1: ', metrics.f1_score(y_true,y_pred,average='weighted'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T03:02:14.285381Z",
     "start_time": "2017-07-19T03:02:14.143374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** three-class case balanced ********************\n",
      "cfm: \n",
      " [[0 1 1]\n",
      " [0 2 0]\n",
      " [0 1 1]]\n",
      "auc:  [0.6875, 1.0, 0.8125]\n",
      "micro auc:  0.805555555556\n",
      "macro auc:  0.833333333333\n",
      "f1 :  [ 0.          0.66666667  0.5       ]\n",
      "micro f1:  0.5\n",
      "macro f1:  0.388888888889\n",
      "weighted f1:  0.388888888889\n",
      "accuracy:  0.5\n",
      "******************** three-class case unbalanced ********************\n",
      "cfm: \n",
      " [[0 5 5]\n",
      " [0 2 0]\n",
      " [0 1 1]]\n",
      "auc:  [0.6875, 1.0, 0.6875]\n",
      "micro auc:  0.647959183673\n",
      "macro auc:  0.791666666667\n",
      "f1 :  [ 0.    0.4   0.25]\n",
      "micro f1:  0.214285714286\n",
      "macro f1:  0.216666666667\n",
      "weighted f1:  0.0928571428571\n",
      "accuracy:  0.214285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# three-class case, balanced\n",
    "\n",
    "# prepare data\n",
    "y_true = np.array([0,0, 1, 1,2, 2])\n",
    "y_score = np.array([[0.3, 0.4, 0.3],\n",
    "                    [0.4,0.1,0.5],\n",
    "                    [0.3,0.6,0.1],\n",
    "                    [0.4,0.5,0.1],\n",
    "                    [0,0.1,0.9],\n",
    "                    [0.3,0.4,0.3]])\n",
    "y_pred = np.argmax(y_score,1)\n",
    "\n",
    "y_true_roc = label_binarize(y_true, classes=[0,1,2])\n",
    "\n",
    "\n",
    "print('*'*20 + ' three-class case balanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[0,1,2]))\n",
    "aucs = []\n",
    "for i in range(3):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score[:,i], pos_label=i)\n",
    "    aucs.append(metrics.auc(fpr, tpr))\n",
    "print('auc: ', aucs)\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_micro, tpr_micro, _ = metrics.roc_curve(y_true_roc.ravel(), y_score.ravel())\n",
    "print('micro auc: ', metrics.auc(fpr_micro, tpr_micro))\n",
    "print('macro auc: ', np.mean(aucs))\n",
    "print('f1 : ', metrics.f1_score(y_true,y_pred,average=None))\n",
    "print('micro f1: ', metrics.f1_score(y_true,y_pred,average='micro'))\n",
    "print('macro f1: ', metrics.f1_score(y_true,y_pred,average='macro'))\n",
    "print('weighted f1: ', metrics.f1_score(y_true,y_pred,average='weighted'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))\n",
    "# three-class case, in balanced\n",
    "\n",
    "# prepare data\n",
    "# duplicate class 0 five times\n",
    "y_true = np.hstack([np.hstack([y_true[:2]]*5),y_true[2:]])\n",
    "y_score =  np.vstack([np.vstack([y_score[:2,:]]*5),y_score[2:,:]])\n",
    "y_pred = np.argmax(y_score,1)\n",
    "\n",
    "y_true_roc = label_binarize(y_true, classes=[0,1,2])\n",
    "\n",
    "    \n",
    "print('*'*20 + ' three-class case unbalanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[0,1,2]))\n",
    "aucs = []\n",
    "for i in range(3):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score[:,i], pos_label=i)\n",
    "    aucs.append(metrics.auc(fpr, tpr))\n",
    "print('auc: ', aucs)\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_micro, tpr_micro, _ = metrics.roc_curve(y_true_roc.ravel(), y_score.ravel())\n",
    "print('micro auc: ', metrics.auc(fpr_micro, tpr_micro))\n",
    "print('macro auc: ', np.mean(aucs))\n",
    "print('f1 : ', metrics.f1_score(y_true,y_pred,average=None))\n",
    "print('micro f1: ', metrics.f1_score(y_true,y_pred,average='micro'))\n",
    "print('macro f1: ', metrics.f1_score(y_true,y_pred,average='macro'))\n",
    "print('weighted f1: ', metrics.f1_score(y_true,y_pred,average='weighted'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class ratio: 10:1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T03:02:14.416582Z",
     "start_time": "2017-07-19T03:02:14.286577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** three-class case balanced ********************\n",
      "cfm: \n",
      " [[2 0 0]\n",
      " [0 2 0]\n",
      " [0 1 1]]\n",
      "auc:  [1.0, 1.0, 1.0]\n",
      "micro auc:  0.944444444444\n",
      "macro auc:  1.0\n",
      "f1 :  [ 1.          0.8         0.66666667]\n",
      "micro f1:  0.833333333333\n",
      "macro f1:  0.822222222222\n",
      "weighted f1:  0.822222222222\n",
      "accuracy:  0.833333333333\n",
      "******************** three-class case unbalanced ********************\n",
      "cfm: \n",
      " [[20  0  0]\n",
      " [ 0  2  0]\n",
      " [ 0  1  1]]\n",
      "auc:  [1.0, 1.0, 1.0]\n",
      "micro auc:  0.988715277778\n",
      "macro auc:  1.0\n",
      "f1 :  [ 1.          0.8         0.66666667]\n",
      "micro f1:  0.958333333333\n",
      "macro f1:  0.822222222222\n",
      "weighted f1:  0.955555555556\n",
      "accuracy:  0.958333333333\n"
     ]
    }
   ],
   "source": [
    "# three-class case, balanced\n",
    "\n",
    "# prepare data\n",
    "y_true = np.array([0,0, 1, 1,2, 2])\n",
    "y_score = np.array([[0.5, 0.4, 0.1],\n",
    "                    [0.8,0.1,0.1],\n",
    "                    [0.3,0.6,0.1],\n",
    "                    [0.4,0.5,0.1],\n",
    "                    [0,0.1,0.9],\n",
    "                    [0.3,0.4,0.3]])\n",
    "y_pred = np.argmax(y_score,1)\n",
    "\n",
    "y_true_roc = label_binarize(y_true, classes=[0,1,2])\n",
    "\n",
    "\n",
    "print('*'*20 + ' three-class case balanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[0,1,2]))\n",
    "aucs = []\n",
    "for i in range(3):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score[:,i], pos_label=i)\n",
    "    aucs.append(metrics.auc(fpr, tpr))\n",
    "print('auc: ', aucs)\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_micro, tpr_micro, _ = metrics.roc_curve(y_true_roc.ravel(), y_score.ravel())\n",
    "print('micro auc: ', metrics.auc(fpr_micro, tpr_micro))\n",
    "print('macro auc: ', np.mean(aucs))\n",
    "print('f1 : ', metrics.f1_score(y_true,y_pred,average=None))\n",
    "print('micro f1: ', metrics.f1_score(y_true,y_pred,average='micro'))\n",
    "print('macro f1: ', metrics.f1_score(y_true,y_pred,average='macro'))\n",
    "print('weighted f1: ', metrics.f1_score(y_true,y_pred,average='weighted'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))\n",
    "# three-class case, in balanced\n",
    "\n",
    "# prepare data\n",
    "# duplicate class 0 five times\n",
    "y_true = np.hstack([np.hstack([y_true[:2]]*10),y_true[2:]])\n",
    "y_score =  np.vstack([np.vstack([y_score[:2,:]]*10),y_score[2:,:]])\n",
    "y_pred = np.argmax(y_score,1)\n",
    "\n",
    "y_true_roc = label_binarize(y_true, classes=[0,1,2])\n",
    "\n",
    "    \n",
    "print('*'*20 + ' three-class case unbalanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[0,1,2]))\n",
    "aucs = []\n",
    "for i in range(3):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score[:,i], pos_label=i)\n",
    "    aucs.append(metrics.auc(fpr, tpr))\n",
    "print('auc: ', aucs)\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_micro, tpr_micro, _ = metrics.roc_curve(y_true_roc.ravel(), y_score.ravel())\n",
    "print('micro auc: ', metrics.auc(fpr_micro, tpr_micro))\n",
    "print('macro auc: ', np.mean(aucs))\n",
    "print('f1 : ', metrics.f1_score(y_true,y_pred,average=None))\n",
    "print('micro f1: ', metrics.f1_score(y_true,y_pred,average='micro'))\n",
    "print('macro f1: ', metrics.f1_score(y_true,y_pred,average='macro'))\n",
    "print('weighted f1: ', metrics.f1_score(y_true,y_pred,average='weighted'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T03:02:14.542766Z",
     "start_time": "2017-07-19T03:02:14.418509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** three-class case balanced ********************\n",
      "cfm: \n",
      " [[1 1 0]\n",
      " [0 2 0]\n",
      " [0 1 1]]\n",
      "auc:  [0.75, 1.0, 0.9375]\n",
      "micro auc:  0.875\n",
      "macro auc:  0.895833333333\n",
      "f1 :  [ 0.66666667  0.66666667  0.66666667]\n",
      "micro f1:  0.666666666667\n",
      "macro f1:  0.666666666667\n",
      "weighted f1:  0.666666666667\n",
      "accuracy:  0.666666666667\n",
      "******************** three-class case unbalanced ********************\n",
      "cfm: \n",
      " [[10 10  0]\n",
      " [ 0  2  0]\n",
      " [ 0  1  1]]\n",
      "auc:  [0.75, 1.0, 0.88636363636363624]\n",
      "micro auc:  0.828125\n",
      "macro auc:  0.878787878788\n",
      "f1 :  [ 0.66666667  0.26666667  0.66666667]\n",
      "micro f1:  0.541666666667\n",
      "macro f1:  0.533333333333\n",
      "weighted f1:  0.633333333333\n",
      "accuracy:  0.541666666667\n"
     ]
    }
   ],
   "source": [
    "# three-class case, balanced\n",
    "\n",
    "# prepare data\n",
    "y_true = np.array([0,0, 1, 1,2, 2])\n",
    "y_score = np.array([[0.3, 0.4, 0.3],\n",
    "                    [0.8,0.1,0.1],\n",
    "                    [0.3,0.6,0.1],\n",
    "                    [0.4,0.5,0.1],\n",
    "                    [0,0.1,0.9],\n",
    "                    [0.3,0.4,0.3]])\n",
    "y_pred = np.argmax(y_score,1)\n",
    "\n",
    "y_true_roc = label_binarize(y_true, classes=[0,1,2])\n",
    "\n",
    "\n",
    "print('*'*20 + ' three-class case balanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[0,1,2]))\n",
    "aucs = []\n",
    "for i in range(3):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score[:,i], pos_label=i)\n",
    "    aucs.append(metrics.auc(fpr, tpr))\n",
    "print('auc: ', aucs)\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_micro, tpr_micro, _ = metrics.roc_curve(y_true_roc.ravel(), y_score.ravel())\n",
    "print('micro auc: ', metrics.auc(fpr_micro, tpr_micro))\n",
    "print('macro auc: ', np.mean(aucs))\n",
    "print('f1 : ', metrics.f1_score(y_true,y_pred,average=None))\n",
    "print('micro f1: ', metrics.f1_score(y_true,y_pred,average='micro'))\n",
    "print('macro f1: ', metrics.f1_score(y_true,y_pred,average='macro'))\n",
    "print('weighted f1: ', metrics.f1_score(y_true,y_pred,average='weighted'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))\n",
    "# three-class case, in balanced\n",
    "\n",
    "# prepare data\n",
    "# duplicate class 0 five times\n",
    "y_true = np.hstack([np.hstack([y_true[:2]]*10),y_true[2:]])\n",
    "y_score =  np.vstack([np.vstack([y_score[:2,:]]*10),y_score[2:,:]])\n",
    "y_pred = np.argmax(y_score,1)\n",
    "\n",
    "y_true_roc = label_binarize(y_true, classes=[0,1,2])\n",
    "\n",
    "    \n",
    "print('*'*20 + ' three-class case unbalanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[0,1,2]))\n",
    "aucs = []\n",
    "for i in range(3):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score[:,i], pos_label=i)\n",
    "    aucs.append(metrics.auc(fpr, tpr))\n",
    "print('auc: ', aucs)\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_micro, tpr_micro, _ = metrics.roc_curve(y_true_roc.ravel(), y_score.ravel())\n",
    "print('micro auc: ', metrics.auc(fpr_micro, tpr_micro))\n",
    "print('macro auc: ', np.mean(aucs))\n",
    "print('f1 : ', metrics.f1_score(y_true,y_pred,average=None))\n",
    "print('micro f1: ', metrics.f1_score(y_true,y_pred,average='micro'))\n",
    "print('macro f1: ', metrics.f1_score(y_true,y_pred,average='macro'))\n",
    "print('weighted f1: ', metrics.f1_score(y_true,y_pred,average='weighted'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T03:02:14.685203Z",
     "start_time": "2017-07-19T03:02:14.543857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** three-class case balanced ********************\n",
      "cfm: \n",
      " [[0 2 0]\n",
      " [0 2 0]\n",
      " [0 1 1]]\n",
      "auc:  [0.6875, 0.9375, 0.9375]\n",
      "micro auc:  0.805555555556\n",
      "macro auc:  0.854166666667\n",
      "f1 :  [ 0.          0.57142857  0.66666667]\n",
      "micro f1:  0.5\n",
      "macro f1:  0.412698412698\n",
      "weighted f1:  0.412698412698\n",
      "accuracy:  0.5\n",
      "******************** three-class case unbalanced ********************\n",
      "cfm: \n",
      " [[ 0 20  0]\n",
      " [ 0  2  0]\n",
      " [ 0  1  1]]\n",
      "auc:  [0.6875, 0.88636363636363624, 0.88636363636363624]\n",
      "micro auc:  0.589409722222\n",
      "macro auc:  0.820075757576\n",
      "f1 :  [ 0.          0.16        0.66666667]\n",
      "micro f1:  0.125\n",
      "macro f1:  0.275555555556\n",
      "weighted f1:  0.0688888888889\n",
      "accuracy:  0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# three-class case, balanced\n",
    "\n",
    "# prepare data\n",
    "y_true = np.array([0,0, 1, 1,2, 2])\n",
    "y_score = np.array([[0.3, 0.4, 0.3],\n",
    "                    [0.4,0.5,0.1],\n",
    "                    [0.3,0.6,0.1],\n",
    "                    [0.4,0.5,0.1],\n",
    "                    [0,0.1,0.9],\n",
    "                    [0.3,0.4,0.3]])\n",
    "y_pred = np.argmax(y_score,1)\n",
    "\n",
    "y_true_roc = label_binarize(y_true, classes=[0,1,2])\n",
    "\n",
    "\n",
    "print('*'*20 + ' three-class case balanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[0,1,2]))\n",
    "aucs = []\n",
    "for i in range(3):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score[:,i], pos_label=i)\n",
    "    aucs.append(metrics.auc(fpr, tpr))\n",
    "print('auc: ', aucs)\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_micro, tpr_micro, _ = metrics.roc_curve(y_true_roc.ravel(), y_score.ravel())\n",
    "print('micro auc: ', metrics.auc(fpr_micro, tpr_micro))\n",
    "print('macro auc: ', np.mean(aucs))\n",
    "print('f1 : ', metrics.f1_score(y_true,y_pred,average=None))\n",
    "print('micro f1: ', metrics.f1_score(y_true,y_pred,average='micro'))\n",
    "print('macro f1: ', metrics.f1_score(y_true,y_pred,average='macro'))\n",
    "print('weighted f1: ', metrics.f1_score(y_true,y_pred,average='weighted'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))\n",
    "# three-class case, in balanced\n",
    "\n",
    "# prepare data\n",
    "# duplicate class 0 five times\n",
    "y_true = np.hstack([np.hstack([y_true[:2]]*10),y_true[2:]])\n",
    "y_score =  np.vstack([np.vstack([y_score[:2,:]]*10),y_score[2:,:]])\n",
    "y_pred = np.argmax(y_score,1)\n",
    "\n",
    "y_true_roc = label_binarize(y_true, classes=[0,1,2])\n",
    "\n",
    "    \n",
    "print('*'*20 + ' three-class case unbalanced '+ '*'*20)\n",
    "print('cfm: \\n', metrics.confusion_matrix(y_true,y_pred,labels=[0,1,2]))\n",
    "aucs = []\n",
    "for i in range(3):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_score[:,i], pos_label=i)\n",
    "    aucs.append(metrics.auc(fpr, tpr))\n",
    "print('auc: ', aucs)\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_micro, tpr_micro, _ = metrics.roc_curve(y_true_roc.ravel(), y_score.ravel())\n",
    "print('micro auc: ', metrics.auc(fpr_micro, tpr_micro))\n",
    "print('macro auc: ', np.mean(aucs))\n",
    "print('f1 : ', metrics.f1_score(y_true,y_pred,average=None))\n",
    "print('micro f1: ', metrics.f1_score(y_true,y_pred,average='micro'))\n",
    "print('macro f1: ', metrics.f1_score(y_true,y_pred,average='macro'))\n",
    "print('weighted f1: ', metrics.f1_score(y_true,y_pred,average='weighted'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_true,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
